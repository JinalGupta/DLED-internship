{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnXS7s6wgSWh"
      },
      "outputs": [],
      "source": [
        "!pip install vosk ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install ffmpeg"
      ],
      "metadata": {
        "id": "QbfHueyhgqB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Hindi model\n",
        "!wget https://alphacephei.com/vosk/models/vosk-model-hi-0.22.zip\n",
        "!unzip vosk-model-hi-0.22.zip"
      ],
      "metadata": {
        "id": "0IkmW1MtgwVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download English model\n",
        "!wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
        "!unzip vosk-model-small-en-us-0.15.zip"
      ],
      "metadata": {
        "id": "bOw2yMdJgyyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SpeechRecognition"
      ],
      "metadata": {
        "id": "oxXKWo1BiMZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speechrecognition"
      ],
      "metadata": {
        "id": "4rbbGRfpjYyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "uSBGXQeIkHPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_to_wav(input_file, output_file):\n",
        "    \"\"\"Convert audio file to WAV format.\"\"\"\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "    audio.export(output_file, format='wav')\n",
        "    print(\"‚úÖ Conversion to WAV successful!\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Transcribe audio file to text using Google's Speech Recognition API.\"\"\"\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        print(\"üîç Processing audio...\")\n",
        "        audio = recognizer.record(source)\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        print(\"‚úÖ Transcription Successful!\\n\")\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"‚ö†Ô∏è Could not understand the audio.\"\n",
        "    except sr.RequestError:\n",
        "        return \"‚ö†Ô∏è Could not connect to the speech recognition service.\"\n",
        "\n",
        "# Convert to WAV\n",
        "input_file = \"/content/WhatsApp Audio 2025-03-05 at 09.43.53_2247dcdf.dat.unknown\"\n",
        "wav_file = \"/content/converted_audio.wav\"\n",
        "convert_to_wav(input_file, wav_file)\n",
        "\n",
        "# Transcribe\n",
        "transcribed_text = transcribe_audio(wav_file)\n",
        "print(\"üìù Transcribed Text:\\n\", transcribed_text)"
      ],
      "metadata": {
        "id": "ABKvBFghhT4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "id": "c6gMOpuihnO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def convert_wav_to_mp3(wav_file, mp3_file=None):\n",
        "    # Load the WAV file\n",
        "    audio = AudioSegment.from_wav(wav_file)\n",
        "\n",
        "    # Set output file name if not provided\n",
        "    if not mp3_file:\n",
        "        mp3_file = wav_file.rsplit('.', 1)[0] + \".mp3\"\n",
        "\n",
        "    # Export as MP3\n",
        "    audio.export(mp3_file, format=\"mp3\")\n",
        "\n",
        "    print(f\"Conversion complete: {mp3_file}\")\n",
        "\n",
        "# Example usage\n",
        "convert_wav_to_mp3(\"/content/converted_audio.wav\")"
      ],
      "metadata": {
        "id": "A3YNVG2isHbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def transcribe_audio(audio_file, model_size=\"base\"):\n",
        "    # Load the Whisper model\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    # Transcribe the audio file\n",
        "    result = model.transcribe(audio_file)\n",
        "\n",
        "    # Save transcript to a file\n",
        "    transcript_file = audio_file.rsplit('.', 1)[0] + \"_transcript.txt\"\n",
        "    with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(result[\"text\"])\n",
        "\n",
        "    print(f\"Transcription saved to {transcript_file}\")\n",
        "    return result[\"text\"]\n",
        "\n",
        "# Example usage\n",
        "audio_path = \"/content/converted_audio.mp3\"  # Change this to your actual file\n",
        "transcript = transcribe_audio(audio_path)\n",
        "print(\"Transcript:\",transcript)"
      ],
      "metadata": {
        "id": "7exXQPwTr5kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "KKMCR1f0vGyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create the interface for the above using streamlit\n",
        "\n",
        "import streamlit as st\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "import whisper\n",
        "\n",
        "def convert_to_wav(input_file, output_file):\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "    audio.export(output_file, format='wav')\n",
        "    st.write(\"‚úÖ Conversion to WAV successful!\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        st.write(\"‚úÖ Transcription Successful!\\n\")\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"‚ö†Ô∏è Could not understand the audio.\"\n",
        "    except sr.RequestError:\n",
        "        return \"‚ö†Ô∏è Could not connect to the speech recognition service.\"\n",
        "\n",
        "def convert_wav_to_mp3(wav_file, mp3_file=None):\n",
        "    audio = AudioSegment.from_wav(wav_file)\n",
        "    if not mp3_file:\n",
        "        mp3_file = wav_file.rsplit('.', 1)[0] + \".mp3\"\n",
        "    audio.export(mp3_file, format=\"mp3\")\n",
        "    st.write(f\"Conversion complete: {mp3_file}\")\n",
        "\n",
        "def transcribe_audio_whisper(audio_file, model_size=\"base\"):\n",
        "    model = whisper.load_model(model_size)\n",
        "    result = model.transcribe(audio_file)\n",
        "    transcript_file = audio_file.rsplit('.', 1)[0] + \"_transcript.txt\"\n",
        "    with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(result[\"text\"])\n",
        "    st.write(f\"Transcription saved to {transcript_file}\")\n",
        "    return result[\"text\"]\n",
        "\n",
        "st.title(\"Audio Transcription App\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an audio file\", type=[\"wav\", \"mp3\", \"ogg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Save the uploaded file\n",
        "    with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "        f.write(uploaded_file.getvalue())\n",
        "\n",
        "    # Perform transcription\n",
        "    if st.button(\"Transcribe\"):\n",
        "        wav_file = \"uploaded_audio.wav\"\n",
        "        mp3_file = \"uploaded_audio.mp3\"\n",
        "        convert_to_wav(\"uploaded_audio.wav\", wav_file)\n",
        "        convert_wav_to_mp3(wav_file, mp3_file)\n",
        "        transcript = transcribe_audio_whisper(mp3_file)\n",
        "        st.write(\"üìù Transcribed Text:\\n\", transcript)"
      ],
      "metadata": {
        "id": "sJJoG5Fru8KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "JPeeKZqKvFlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "import whisper\n",
        "\n",
        "def convert_to_wav(input_file, output_file):\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "    audio.export(output_file, format='wav')\n",
        "    st.write(\"‚úÖ Conversion to WAV successful!\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        st.write(\"‚úÖ Transcription Successful!\\n\")\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"‚ö†Ô∏è Could not understand the audio.\"\n",
        "    except sr.RequestError:\n",
        "        return \"‚ö†Ô∏è Could not connect to the speech recognition service.\"\n",
        "\n",
        "def convert_wav_to_mp3(wav_file, mp3_file=None):\n",
        "    audio = AudioSegment.from_wav(wav_file)\n",
        "    if not mp3_file:\n",
        "        mp3_file = wav_file.rsplit('.', 1)[0] + \".mp3\"\n",
        "    audio.export(mp3_file, format=\"mp3\")\n",
        "    st.write(f\"Conversion complete: {mp3_file}\")\n",
        "\n",
        "def transcribe_audio_whisper(audio_file, model_size=\"base\"):\n",
        "    model = whisper.load_model(model_size)\n",
        "    result = model.transcribe(audio_file)\n",
        "    transcript_file = audio_file.rsplit('.', 1)[0] + \"_transcript.txt\"\n",
        "    with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(result[\"text\"])\n",
        "    st.write(f\"Transcription saved to {transcript_file}\")\n",
        "    return result[\"text\"]\n",
        "\n",
        "st.title(\"Audio Transcription App\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an audio file\", type=[\"wav\", \"mp3\", \"ogg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Save the uploaded file\n",
        "    with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "        f.write(uploaded_file.getvalue())\n",
        "\n",
        "    # Perform transcription\n",
        "    if st.button(\"Transcribe\"):\n",
        "        wav_file = \"uploaded_audio.wav\"\n",
        "        mp3_file = \"uploaded_audio.mp3\"\n",
        "        convert_to_wav(\"uploaded_audio.wav\", wav_file)\n",
        "        convert_wav_to_mp3(wav_file, mp3_file)\n",
        "        transcript = transcribe_audio_whisper(mp3_file)\n",
        "        st.write(\"üìù Transcribed Text:\\n\", transcript)\n",
        "\n",
        "import base64\n",
        "\n",
        "# Display the transcribed text\n",
        "st.write(\"üìù Transcribed Text:\\n\",transcript)\n",
        "\n",
        "# Provide a download button for the transcript\n",
        "with open(\"uploaded_audio_transcript.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    transcript_content = file.read()\n",
        "\n",
        "# Create a download link for the .txt file\n",
        "st.download_button(\n",
        "    label=\"üì• Download Transcript as .txt\",\n",
        "    data=transcript_content,\n",
        "    file_name=\"uploaded_audio_transcript.txt\",\n",
        "    mime=\"text/plain\"\n",
        ")"
      ],
      "metadata": {
        "id": "tqiwdo5lwJUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fuser 8501/tcp -k"
      ],
      "metadata": {
        "id": "RGp7wm_Pzhw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok"
      ],
      "metadata": {
        "id": "SbZJjE6I9g3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8502)  # Change to 8502 or any other free port\n",
        "print(f\"üöÄ Streamlit app is live at: {public_url}\")"
      ],
      "metadata": {
        "id": "rg4IAvC-9imK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Start Streamlit in a separate thread\n",
        "def run_streamlit():\n",
        "    !streamlit run app.py --server.port 8502\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.start()\n",
        "\n",
        "# Give Streamlit some time to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Create a public URL using ngrok\n",
        "public_url = ngrok.connect(8502)\n",
        "print(f\"üöÄ Streamlit app is live at: {public_url}\")\n"
      ],
      "metadata": {
        "id": "pX_0BK5swZsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2tssscRRTIeUkSZwCRcBUy14amY_2rS11ZXrVrzt4kVzVriC4"
      ],
      "metadata": {
        "id": "DkAa1O2Kxpe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A wild code"
      ],
      "metadata": {
        "id": "hRVws0kDwclG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Path to your audio file\n",
        "audio_file = \"/content/converted_audio.wav\"  # Replace with the path to your audio\n",
        "\n",
        "# Transcribe audio\n",
        "transcription = model.transcribe(audio_file)\n",
        "transcription_text = transcription['text']\n",
        "\n",
        "print(\"Transcription:\\n\", transcription_text)"
      ],
      "metadata": {
        "id": "uS4uZ6Zc_CYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save the text file\n",
        "text_file_path = \"/content/transcription.txt\"  # Change path if needed\n",
        "\n",
        "# Save the transcription to a text file\n",
        "with open(text_file_path, 'w') as file:\n",
        "    file.write(\"Transcription:\\n\" + transcription_text)\n",
        "\n",
        "print(f\"Transcription saved successfully at: {text_file_path}\")"
      ],
      "metadata": {
        "id": "zanb_QX4_IU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hosting it on a localhost"
      ],
      "metadata": {
        "id": "Wxbk6YllEFn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import whisper\n",
        "import os\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"Speech-to-Text App\", page_icon=\"üéôÔ∏è\")\n",
        "\n",
        "# Title and description\n",
        "st.title(\"üéôÔ∏è Speech-to-Text Transcription\")\n",
        "st.write(\"Upload an audio file to get the transcription as text!\")\n",
        "\n",
        "# Upload audio file\n",
        "audio_file = st.file_uploader(\"Upload Audio\", type=[\"wav\", \"mp3\", \"m4a\"])\n",
        "\n",
        "# Transcription function\n",
        "def transcribe_audio(file_path):\n",
        "    # Load Whisper model\n",
        "    model = whisper.load_model(\"base\")\n",
        "    # Transcribe audio\n",
        "    transcription = model.transcribe(file_path)\n",
        "    return transcription['text']\n",
        "\n",
        "if audio_file is not None:\n",
        "    # Save uploaded file temporarily\n",
        "    with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "        f.write(audio_file.getbuffer())\n",
        "\n",
        "    st.audio(audio_file, format='audio/wav')\n",
        "\n",
        "    # Perform transcription\n",
        "    with st.spinner(\"Transcribing... Please wait...\"):\n",
        "        transcription_text = transcribe_audio(\"uploaded_audio.wav\")\n",
        "        st.success(\"Transcription complete!\")\n",
        "\n",
        "        # Display transcription\n",
        "        st.text_area(\"Transcription:\", transcription_text, height=300)\n",
        "\n",
        "        # Save transcription to a text file\n",
        "        text_file_path = \"transcription.txt\"\n",
        "        with open(text_file_path, 'w') as file:\n",
        "            file.write(\"Transcription:\\n\" + transcription_text)\n",
        "\n",
        "        # Provide download link for the text file\n",
        "        with open(text_file_path, 'rb') as f:\n",
        "            st.download_button(\n",
        "                label=\"Download Transcription as Text File\",\n",
        "                data=f,\n",
        "                file_name=\"transcription.txt\",\n",
        "                mime=\"text/plain\"\n",
        "            )\n",
        "\n",
        "        # Clean up temporary files\n",
        "        os.remove(\"uploaded_audio.wav\")\n",
        "        os.remove(text_file_path)\n",
        "else:\n",
        "    st.info(\"Please upload an audio file to proceed.\")"
      ],
      "metadata": {
        "id": "lT0awNo8BGj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and run ngrok\n",
        "!pip install pyngrok\n",
        "!ngrok authtoken YOUR_NGROK_AUTH_TOKEN  # Replace YOUR_NGROK_AUTH_TOKEN with your ngrok token\n",
        "\n",
        "# Run Streamlit in the background\n",
        "import threading\n",
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Start Streamlit app\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\"])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "# Create a public URL using ngrok\n",
        "public_url = ngrok.connect(850)\n",
        "print(\"Streamlit app is live at:\", public_url)"
      ],
      "metadata": {
        "id": "CALWojHdBxWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok"
      ],
      "metadata": {
        "id": "5opdVDR6B4D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://localhost:4040/api/tunnels"
      ],
      "metadata": {
        "id": "rYNq_29GCfJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "id": "8JQbpuXgCjlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Streamlit app and use localtunnel for a public URL\n",
        "import threading\n",
        "import subprocess\n",
        "\n",
        "# Start Streamlit in the background\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "# Use localtunnel to expose the Streamlit app\n",
        "!lt --port 8501 --subdomain $(openssl rand -hex 4)"
      ],
      "metadata": {
        "id": "bCpZMcyrC51o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloudflared"
      ],
      "metadata": {
        "id": "qCt2GHQSC9uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb"
      ],
      "metadata": {
        "id": "qSFHL8IUE-cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import subprocess\n",
        "\n",
        "# Start Streamlit app in the background\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\"])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "# Expose the app using cloudflared\n",
        "!cloudflared tunnel --url http://localhost:8501"
      ],
      "metadata": {
        "id": "_FxgzlP4EDMH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}