{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DO NOT RUN ALL THE CODES ON COLAB"
      ],
      "metadata": {
        "id": "JCqKTk7IyVU5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQQOchMiavLj"
      },
      "outputs": [],
      "source": [
        "pip install yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Library to automate cookie downloading\n",
        "USE VS Code"
      ],
      "metadata": {
        "id": "vbJd_tQXu41p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium"
      ],
      "metadata": {
        "id": "dO_lOWH-u8v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install undetected-chromedriver"
      ],
      "metadata": {
        "id": "AjDm_3Ztu9wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install webdriver-manager"
      ],
      "metadata": {
        "id": "XMIU6IIwvBgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install setuptools"
      ],
      "metadata": {
        "id": "TU2HYtREvLFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAB3iETsa7Xw"
      },
      "source": [
        "# Video to Audio generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ-q8Ogca6Xu"
      },
      "outputs": [],
      "source": [
        "import undetected_chromedriver as uc\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By  # <-- Added import\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import time\n",
        "import pickle\n",
        "import yt_dlp\n",
        "import os\n",
        "\n",
        "# Launch Chrome using webdriver_manager\n",
        "options = webdriver.ChromeOptions()\n",
        "browser = uc.Chrome(executable_path=ChromeDriverManager().install(), options=options)\n",
        "\n",
        "# Open Gmail login page\n",
        "browser.get(\"https://accounts.google.com/signin/v2/identifier?continue=https%3A%2F%2Fmail.google.com%2Fmail%2F&service=mail&sacu=1&rip=1&hl=en&flowName=GlifWebSignIn&flowEntry=ServiceLogin\")\n",
        "\n",
        "# Your email and password (replace these with your actual Gmail credentials)\n",
        "email = \"email_id@gmail.com\"\n",
        "password = \"password\"\n",
        "\n",
        "# Enter email and click 'Next'\n",
        "browser.find_element(By.ID, 'identifierId').send_keys(email)\n",
        "browser.find_element(By.CSS_SELECTOR, '#identifierNext > div > button > span').click()\n",
        "\n",
        "# Wait for the password field to appear\n",
        "password_selector = \"#password > div.aCsJod.oJeWuf > div > div.Xb9hP > input\"\n",
        "WebDriverWait(browser, 10).until(\n",
        "    EC.visibility_of_element_located((By.CSS_SELECTOR, password_selector)))\n",
        "\n",
        "# Enter the password and click 'Next'\n",
        "browser.find_element(By.CSS_SELECTOR, password_selector).send_keys(password)\n",
        "browser.find_element(By.CSS_SELECTOR, '#passwordNext > div > button > span').click()\n",
        "\n",
        "# Wait for Gmail to load\n",
        "time.sleep(5)\n",
        "\n",
        "# Get the cookies after login\n",
        "cookies = browser.get_cookies()\n",
        "\n",
        "# Save the cookies to a file\n",
        "with open(\"cookies.pkl\", \"wb\") as cookie_file:\n",
        "    pickle.dump(cookies, cookie_file)\n",
        "\n",
        "print(\"✅ Cookies downloaded successfully!\")\n",
        "\n",
        "\n",
        "# Function to get the base directory dynamically (works across devices)\n",
        "def get_base_path():\n",
        "    return os.path.dirname(os.path.realpath(__file__))\n",
        "\n",
        "def download_audio(video_url):\n",
        "    # Load cookies from the saved file\n",
        "    cookies_file = os.path.join(get_base_path(), 'cookies.pkl')  # Update the path to match the location of the saved cookies\n",
        "    with open(cookies_file, \"rb\") as f:\n",
        "        cookies = pickle.load(f)\n",
        "\n",
        "    # Dynamically determine the output path where the audio file will be saved\n",
        "    audio_path = os.path.join(get_base_path(), 'audio.mp3')\n",
        "\n",
        "    # yt-dlp options for downloading audio\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': audio_path,  # Path where you want to save the audio\n",
        "        'cookies': cookies,  # Use cookies directly\n",
        "    }\n",
        "\n",
        "    # Download audio using yt-dlp\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([video_url])\n",
        "\n",
        "    return audio_path\n",
        "\n",
        "# Prompt for video URL and call the function\n",
        "video_url = input(\"Enter YouTube video URL: \")\n",
        "file_path = download_audio(video_url)\n",
        "print(f\"Downloaded audio: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_08PMhVDbAyG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check the files in /content directory\n",
        "print(\"Files in content:\", os.listdir(\"/content\"))\n",
        "\n",
        "# Fix the file name if needed\n",
        "old_path = \"/content/audio.mp3.mp3\"\n",
        "new_path = \"/content/audio.mp3\"\n",
        "\n",
        "if os.path.exists(old_path):\n",
        "    os.rename(old_path, new_path)\n",
        "    print(f\"Renamed: {old_path} → {new_path}\")\n",
        "else:\n",
        "    print(\"Audio file not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Ipython"
      ],
      "metadata": {
        "id": "UrW6GguLJNLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUMBziRWbBdg"
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "# Set the correct file path\n",
        "audio_path = \"/content/audio.mp3\"\n",
        "\n",
        "# Play the audio with the correct sample rate (e.g., 44100 Hz)\n",
        "ipd.Audio(audio_path, rate=44100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuRQTi-ZbDNy"
      },
      "source": [
        "# Audio to Transcript Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH_m9VOCbGPU"
      },
      "outputs": [],
      "source": [
        "!pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duEFqkbcbNw_"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import re\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"medium\")  # Try \"medium\" or \"large\" for better accuracy\n",
        "result = model.transcribe(\"/content/0403 (1)(1).MP3\", word_timestamps=True)\n",
        "\n",
        "# Function to split text into sentences using punctuation\n",
        "def split_sentences_with_timestamps(segments):\n",
        "    sentences = []\n",
        "    current_sentence = []\n",
        "    start_time, end_time = None, None\n",
        "\n",
        "    for segment in segments:\n",
        "        words = segment[\"words\"]\n",
        "        for word in words:\n",
        "            if start_time is None:\n",
        "                start_time = word[\"start\"]\n",
        "            end_time = word[\"end\"]\n",
        "            current_sentence.append(word[\"word\"])\n",
        "\n",
        "            # Check if sentence-ending punctuation is found\n",
        "            if re.search(r'[.!?]', word[\"word\"].strip()):\n",
        "                sentence_text = \" \".join(current_sentence).strip()\n",
        "                if sentence_text:\n",
        "                    sentences.append({\n",
        "                        \"text\": sentence_text,\n",
        "                        \"start\": start_time,\n",
        "                        \"end\": end_time\n",
        "                    })\n",
        "                # Reset for next sentence\n",
        "                current_sentence = []\n",
        "                start_time, end_time = None, None\n",
        "\n",
        "    # Add remaining sentence if any\n",
        "    if current_sentence:\n",
        "        sentence_text = \" \".join(current_sentence).strip()\n",
        "        if sentence_text:\n",
        "            sentences.append({\n",
        "                \"text\": sentence_text,\n",
        "                \"start\": start_time,\n",
        "                \"end\": end_time\n",
        "            })\n",
        "\n",
        "    return sentences\n",
        "\n",
        "# Split sentences with proper punctuation\n",
        "sentence_segments = split_sentences_with_timestamps(result[\"segments\"])\n",
        "\n",
        "# Save sentence-level transcript with proper sentence boundaries\n",
        "with open(\"/content/sentence_timestamps.txt\", \"w\") as f:\n",
        "    for seg in sentence_segments:\n",
        "        start_time = seg['start']\n",
        "        end_time = seg['end']\n",
        "        text = seg['text']\n",
        "        f.write(f\"{start_time:.2f} --> {end_time:.2f}\\n{text}\\n\\n\")\n",
        "\n",
        "print(\"Sentence-level transcript with accurate timestamps saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmenting Transcripts based on the contexts and topic"
      ],
      "metadata": {
        "id": "BlZ6Ttpk8mXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv8DtL9DbPlt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import spacy\n",
        "import numpy as np\n",
        "from scipy.signal import find_peaks\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Load spaCy tokenizer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def load_text_file(file_path):\n",
        "    \"\"\"Load transcript with sentence-level timestamps.\"\"\"\n",
        "    sentences = []\n",
        "    timestamps = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    for i in range(0, len(lines), 3):\n",
        "      if i + 1 >= len(lines):  # Skip if not enough lines left\n",
        "          continue\n",
        "\n",
        "      time_range = lines[i].strip().split(\" --> \")\n",
        "\n",
        "      # Skip invalid time ranges\n",
        "      if len(time_range) != 2:\n",
        "          continue\n",
        "\n",
        "      try:\n",
        "          start_time = float(time_range[0])\n",
        "          end_time = float(time_range[1])\n",
        "      except ValueError:\n",
        "          continue\n",
        "\n",
        "      text = lines[i + 1].strip()\n",
        "\n",
        "      if text:  # Only add if text is not empty\n",
        "          sentences.append(text)\n",
        "          timestamps.append((start_time, end_time))\n",
        "\n",
        "    tokens = [token.text for sent in sentences for token in nlp(sent)]\n",
        "    return sentences, tokens, timestamps\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bigru = nn.GRU(input_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, _ = self.bigru(x)\n",
        "        return h  # h ∈ R^(N × 2H)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.gru = nn.GRU(hidden_dim * 2, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x, hidden_state):\n",
        "        d, hidden_state = self.gru(x, hidden_state)\n",
        "        return d, hidden_state\n",
        "\n",
        "\n",
        "class Pointer(nn.Module):\n",
        "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
        "        super(Pointer, self).__init__()\n",
        "        self.W1 = nn.Linear(encoder_hidden_dim, decoder_hidden_dim)\n",
        "        self.W2 = nn.Linear(decoder_hidden_dim, decoder_hidden_dim)\n",
        "        self.v = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, encoder_outputs, decoder_state):\n",
        "        scores = self.v(torch.tanh(self.W1(encoder_outputs) + self.W2(decoder_state)))\n",
        "        attention_weights = F.softmax(scores, dim=1)\n",
        "        return attention_weights\n",
        "\n",
        "\n",
        "class SEGBOT(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(SEGBOT, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, hidden_dim)\n",
        "        self.decoder = Decoder(hidden_dim)\n",
        "        self.pointer = Pointer(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "    def forward(self, x, start_units):\n",
        "        encoder_outputs = self.encoder(x)\n",
        "        decoder_hidden = torch.zeros(1, x.size(0), self.decoder.hidden_dim).to(x.device)\n",
        "        decoder_inputs = encoder_outputs[:, start_units, :].unsqueeze(1)\n",
        "        decoder_outputs, _ = self.decoder(decoder_inputs, decoder_hidden)\n",
        "        attention_weights = self.pointer(encoder_outputs, decoder_outputs.squeeze(1))\n",
        "        return attention_weights\n",
        "\n",
        "    def segment_text(self, sentences, tokens, timestamps, attention_weights):\n",
        "        \"\"\"Segment text and get start/end timestamps.\"\"\"\n",
        "        attention_weights = attention_weights.squeeze().detach().cpu().numpy()\n",
        "\n",
        "        # Normalize attention weights\n",
        "        attention_weights = (attention_weights - np.min(attention_weights)) / (\n",
        "            np.max(attention_weights) - np.min(attention_weights)\n",
        "        )\n",
        "\n",
        "        # Find peaks in attention scores\n",
        "        peak_indices, _ = find_peaks(attention_weights, height=0.5, distance=5)\n",
        "\n",
        "        if len(peak_indices) == 0:\n",
        "            return [{\"text\": \" \".join(sentences), \"start_time\": timestamps[0][0], \"end_time\": timestamps[-1][1]}]\n",
        "\n",
        "        segments = []\n",
        "        start_idx = 0\n",
        "        for i in peak_indices:\n",
        "          if i > 0 and i - start_idx >= 5:  # Ensure valid range and at least 5 sentences per segment\n",
        "              segment_text = \" \".join(sentences[start_idx:i]).strip()\n",
        "\n",
        "              if segment_text:\n",
        "                  start_time = timestamps[start_idx][0]\n",
        "\n",
        "                  # Check if `i - 1` is within range to prevent out-of-bounds error\n",
        "                  if i - 1 < len(timestamps):\n",
        "                      end_time = timestamps[i - 1][1]\n",
        "                  else:\n",
        "                      end_time = timestamps[-1][1]  # Fallback to the last timestamp\n",
        "\n",
        "                  segments.append({\"text\": segment_text, \"start_time\": start_time, \"end_time\": end_time})\n",
        "\n",
        "              start_idx = i\n",
        "\n",
        "\n",
        "        # Add last segment\n",
        "        last_segment = \" \".join(sentences[start_idx:]).strip()\n",
        "        if last_segment:\n",
        "            start_time = timestamps[start_idx][0]\n",
        "            end_time = timestamps[-1][1]\n",
        "            segments.append({\"text\": last_segment, \"start_time\": start_time, \"end_time\": end_time})\n",
        "\n",
        "        return segments if segments else None\n",
        "\n",
        "\n",
        "# Model Hyperparameters\n",
        "input_dim = 128  # Example input size\n",
        "hidden_dim = 256  # Hidden layer size\n",
        "model = SEGBOT(input_dim, hidden_dim)\n",
        "\n",
        "# Load text file and process with sentence-level timestamps\n",
        "file_path = \"/content/sentence_timestamps.txt\"  # Ensure sentence-level transcript format\n",
        "sentences, tokens, timestamps = load_text_file(file_path)\n",
        "\n",
        "# Example Input (Dummy Tensor)\n",
        "x = torch.randn(1, len(tokens), input_dim)  # Batch size of 1, sequence length based on text\n",
        "start_units = 0\n",
        "output = model(x, start_units)\n",
        "\n",
        "# Segment the text and get timestamps\n",
        "segments = model.segment_text(sentences, tokens, timestamps, output)\n",
        "\n",
        "# Save segmented transcript with timestamps\n",
        "if segments:\n",
        "    with open(\"segmented_transcript_with_timestamps.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, segment in enumerate(segments):\n",
        "            start_time = segment[\"start_time\"]\n",
        "            end_time = segment[\"end_time\"]\n",
        "            text = segment[\"text\"]\n",
        "            f.write(f\"Segment {i+1} [{start_time:.2f}s - {end_time:.2f}s]:\\n{text}\\n\\n\")\n",
        "    print(\"Segmented transcript with timestamps saved successfully.\")\n",
        "else:\n",
        "    print(\"No valid segments found. Terminating execution.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lAB3iETsa7Xw",
        "NuRQTi-ZbDNy"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}